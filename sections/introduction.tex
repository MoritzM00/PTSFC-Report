\section{Introduction}
\label{ch:Introduction}

The prediction of electrical energy demand is vital to effectively manage costs and scale production, which is also reflected in the vast amount of research dedicated to this problem. \Cite{nti_electricity_2020} carried out an extensive literature review on this problem. However, most studies focus on traditional point predictions for short-term or long-term energy demand \parencite[915]{hong_probabilistic_2016}. Therefore, in this project a focus is set on \textbf{short-term probabilistic forecasting} with application to energy demand and bicycle traffic prediction. The aim is to make forecasts more understandable by quantifying the uncertainty of forecasts, which is inherent due to multiple factors at play. Specifically, we employ \textbf{quantile forecasts} as a simple way to quantify this uncertainty, providing both a point forecast as the median and prediction intervals of 50\% and 95\% confidence levels, respectively. For instance, a 95\% central prediction interval can be defined by the 2.5\% and 97.5\% quantiles and it should cover the actual value in 95\% of the cases.

This report generates probabilistic forecasts using traditional tabular regression models, specifically \textbf{Gradient-Boosting Decision Tree} (GBDT) algorithms such as \textsc{XGBoost} \parencite{chen_xgboost_2016} and \textsc{LightGBM} \parencite{ke_lightgbm_2017}. These tree-based models are evaluated against simpler benchmark models, including a historical quantile-based approach and linear quantile regression. The aim is to assess the strengths and limitations of different GBDT implementations for probabilistic forecasting tasks.

The evaluation framework employs \textbf{Time Series Cross-Validation} (TSCV) to ensure robustness across various temporal contexts. The Pinball Loss, a standard metric for assessing quantile forecasts, serves as the primary evaluation criterion. However, in the context of probabilistic forecasting, it is important to assess model calibration in addition to the relative evaluation metrics. A calibration plot provides visual insight, and empirical coverages can be used to assess prediction intervals.
In addition to numerical metrics, visual inspections provide qualitative insights into model behavior.

As mentioned briefly, this study examines the models using two datasets, called \textit{targets}: 1) The \textit{Energy Target} which is Germany's hourly electrical energy consumption \parencite{noauthor_smard_2025} as reported by the German Bundesnetzagentur and 2) the \textit{Bike Target} which corresponds to daily bicycle counts in one specific road in the center of Karlsruhe. Both targets exhibit significant seasonality, and the use of Feature Engineering is promising, thus motivating the adaptation of tabular regressors for the time series application.
The code is made available on Github.\footnote{\href{https://github.com/MoritzM00/proba-forecasting}{https://github.com/MoritzM00/proba-forecasting}} All empirical results, including metrics and plots, can be viewed online using DVC Studio.\footnote{\href{https://studio.datachain.ai/user/MoritzM00/projects/proba-forecasting-jclqxio6ht}{https://studio.datachain.ai/user/MoritzM00/projects/proba-forecasting-jclqxio6ht}}

The report is organized into four sections as follows. First, \cref{ch:Methodology} describes the methodology that we employed in detail, including a description of the weekly forecasting challenge and model evaluation. Second, the models used for probabilistic forecasting are explained in \cref{ch:Models}, and third, the project results are discussed in \cref{ch:Results}. Finally, the conclusions are drawn in \cref{ch:Conclusion}.