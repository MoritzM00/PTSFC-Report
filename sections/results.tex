\newpage
\section{Results}
\label{ch:Results}

In this chapter, the results of the forecasting challenge are discussed. First, in \cref{sec:Results:ComparisonModels}, a comparison of the models is made on the internal validation scheme employed throughout the project to select models. Second, in \cref{sec:Results:Backtest}, a backtest on the time period of the forecasting challenge is performed to evaluate how the models would have performed during the challenge.

\subsection{Comparison of models}
\label{sec:Results:ComparisonModels}

The results of the internal validation scheme using TSCV as described in \cref{sec:Methodology:Evaluation} are shown in \cref{tab:bikes_results} for the Bike Target and in \cref{tab:energy_results} for the Energy Target. 

\begin{table}[htp]
\centering
\resizebox{\columnwidth}{!}{
\begin{tabular}{@{}lrrrrr@{}}
\toprule
Model & Pinball Loss & $\text{IS}_{0.5}$ & $\text{IS}_{0.05}$ & $\text{Cvg}_{0.5}$ & $\text{Cvg}_{0.05}$ \\
\midrule
Benchmark & 1226.14 (± 751.49) & 1343.29 (± 829.37) & 2897.77 (± 2099.89) & 0.53 (± 0.29) & \textbf{0.95 (± 0.13)} \\
Quantile Regression & 1197.41 (± 602.68) & 1311.78 (± 698.27) & 2948.06 (± 1174.44) & \textbf{0.52 (± 0.26)} & 0.98 (± 0.07) \\
CatBoost (Ordered) & 852.67 (± 358.28) & 931.40 (± 402.08) & 1888.97 (± 1164.80) & 0.38 (± 0.21) & 0.85 (± 0.17) \\
XGBoost & 563.99 (± 259.31) & 602.74 (± 279.48) & 1618.93 (± 1114.08) & 0.31 (± 0.20) & 0.84 (± 0.16) \\
CatBoost (Plain) & 539.69 (± 301.24) & \textbf{570.01 (± 313.35)} & 1664.76 (± 1369.76) & 0.36 (± 0.21) & 0.81 (± 0.19) \\
LightGBM & \textbf{529.07 (± 251.59)} & 578.72 (± 285.86) & \textbf{1337.58 (± 646.38)} & 0.36 (± 0.23) & 0.90 (± 0.12) \\
\bottomrule
\end{tabular}}
\caption{Results of time series cross-validation on the Bike Target for the full year 2024 with weekly shifting of sliding windows. The best values are highlighted in bold. \textit{Pinball Loss} refers to the sum of the pinball losses for all quantile levels, averaged over the folds in the TSCV (cf. \cref{sec:Methodology:Evaluation})}
\label{tab:bikes_results}
\end{table}

All GBDT models outperform the baseline models, namely the benchmark and linear quantile regression
regarding the Pinball Loss. However, the empirical coverages are much better for the baseline models.

\begin{table}[htp]
\centering
\resizebox{\columnwidth}{!}{
\begin{tabular}{@{}lrrrrr@{}}
\toprule
Model & Pinball Loss & $\text{IS}_{0.5}$ & $\text{IS}_{0.05}$ & $\text{Cvg}_{0.5}$ & $\text{Cvg}_{0.05}$ \\
\midrule
Benchmark & 5.12 (± 2.68) & 5.60 (± 2.92) & 11.20 (± 6.94) & \textbf{0.52 (± 0.30)} & \textbf{0.94 (± 0.13)} \\
Quantile Regression & 4.49 (± 2.37) & 4.60 (± 2.97) & 17.28 (± 1.61) & 0.47 (± 0.18) & 0.97 (± 0.05) \\
CatBoost (Ordered) & 3.55 (± 1.88) & 3.87 (± 1.92) & 8.59 (± 7.61) & 0.43 (± 0.14) & 0.89 (± 0.13) \\
XGBoost & 2.32 (± 1.21) & 2.47 (± 1.17) & 6.80 (± 6.57) & 0.37 (± 0.12) & 0.81 (± 0.16) \\
LightGBM & 2.30 (± 1.16) & 2.47 (± 1.15) & 6.42 (± 5.58) & 0.38 (± 0.13) & 0.83 (± 0.15) \\
CatBoost (Plain) & \textbf{2.25 (± 1.14)} & \textbf{2.42 (± 1.12)} & \textbf{5.98 (± 5.73)} & 0.39 (± 0.14) & 0.84 (± 0.15) \\
\bottomrule
\end{tabular}}
\caption{Results of time series cross-validation on the Energy Target for the full year 2024 with weekly shifting of sliding windows. The best values are highlighted in bold.}
\label{tab:energy_results}
\end{table}

The coverage of the 95\% prediction interval $\text{Cvg}_{0.05}$ is below 85\% for most GBDT-Models and the coverage for the 50\% prediction interval is even worse. This means that the GBDT models probably still overfit the training data due to the included lagged target values and, thus, are too confident in their predictions. It was observed that too many lags reduce the coverage substantially, but some are lags are needed to reduce the pinball loss. Besides including too many lagged target values, it seemed that including too many weather variables or lagged exogenous variables also made the prediction intervals of the GBDT models narrower. As an example, a visual inspection of the narrow prediction intervals for the CatBoost model is given in the appendix in \cref{fig:Forecast-visualization}.
Only CatBoost achieves better coverage values when the ordered boosting type is used on the Energy
Target, at the cost of a much higher Pinball Loss. This can be visually evaluated with the calibration plots shown in \cref{fig:calibration-comparison}, where the CatBoost calibration (\cref{fig:catboost-ordered-calibration}) is compared to the LightGBM calibration (\cref{fig:lgbm-calibration}).
\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \includesvg[width=\linewidth]{images/catboost-ordered-energy-calibration.svg}
        \caption{CatBoost (Ordered)}
        \label{fig:catboost-ordered-calibration}
    \end{subfigure}%
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \includesvg[width=\linewidth]{images/lgbm-energy-calibration.svg}
        \caption{LightGBM}
        \label{fig:lgbm-calibration}
    \end{subfigure}
    \caption{Calibration plots for two selected models on the Energy Target. It shows that the GBDT models tend to over-estimate the lower quantiles $\hat{q}_{0.025}$, $\hat{q}_{0.25}$ and under-estimate the upper levels $\hat{q}_{0.075}$, $\hat{q}_{0.975}$. CatBoost with the \texttt{boosting\_type=Ordered} parameter set is slightly better calibrated than LightGBM at the cost of a higher Pinball Loss. XGBoost is very similar to LightGBM in this regard.}
    \label{fig:calibration-comparison}
\end{figure}

Calibration plots for all models on both targets, as well as other visualizations can be found in Appendix~\ref{appendix:additional-visualizations}.


CatBoost also supports the standard (Plain) gradient-boosting algorithm,
and with this, it performs on par with LightGBM and even outperforms it slightly on
the Energy Target. However, this is highly hyperparameter-dependent, and the standard
deviation is generally relatively high. The chosen hyper-parameters deviate from the default 
configuration to prevent overfitting and are described in more detail in Appendix~\ref{appendix:GBDT-configs}.\footnote{For example, the default parameters of LightGBM allow for trees with unlimited depth, restricting them only to a maximum of 32 leaves. This can lead to overfitting because nodes are expanded best first during tree construction. In addition, many randomization settings, such as the subsampling of rows and columns, are disabled by default.}


\subsection{Backtest for the weekly forecasting challenge}
\label{sec:Results:Backtest}

\Cref{tab:challenge-backtest} shows the results of a backtest for the weekly forecasting challenge as described in \cref{sec:Methodology:ForecastingChallenge}. The backtest deviates from the exact challenge setup: 1) The performance metrics are computed on a full week of forecasted values, i.e. 168 hours for Energy instead of only 6 hours in the challenge setup. 2) The challenge was paused during winter holidays, but this backtest includes forecasts in this period as well.

% \begin{table}[h]
%     \centering
%     \begin{tabular}{@{}lcccccc@{}}
%         \toprule
%         & \multicolumn{3}{c}{Bike} & \multicolumn{3}{c}{Energy} \\
%         \cmidrule(lr){2-4} \cmidrule(lr){5-7}
%         Model & PB & $\text{Cvg}_{0.5}$ & $\text{Cvg}_{0.05}$ & PB & $\text{Cvg}_{0.5}$ & $\text{Cvg}_{0.05}$ \\
%         \midrule
%         Benchmark & 1453.64 ($\pm$ 1261.92) & 0.51 ($\pm$ 0.32) & 0.92 ($\pm$ 0.21) & 8.46 ($\pm$ 2.84) & 0.21 ($\pm$ 0.29) & 0.84 ($\pm$ 0.16) \\
%         Quantile Regression & 1166.25 ($\pm$ 849.24) & 0.57 ($\pm$ 0.28) & 0.95 ($\pm$ 0.12) & 4.90 ($\pm$ 2.44) & 0.43 ($\pm$ 0.17) & 0.96 ($\pm$ 0.04) \\
%         XGBoost & 569.99 ($\pm$ 258.14) & 0.24 ($\pm$ 0.20) & 0.78 ($\pm$ 0.19) & 2.60 ($\pm$ 0.64) & 0.32 ($\pm$ 0.11) & 0.82 ($\pm$ 0.10) \\
%         CatBoost (Plain) & 624.07 ($\pm$ 302.25) & 0.23 ($\pm$ 0.16) & 0.74 ($\pm$ 0.22) & 2.64 ($\pm$ 0.74) & 0.33 ($\pm$ 0.12) & 0.84 ($\pm$ 0.10) \\
%         LightGBM & 523.57 ($\pm$ 250.23) & 0.39 ($\pm$ 0.18) & 0.86 ($\pm$ 0.21) & 2.57 ($\pm$ 0.63) & 0.34 ($\pm$ 0.11) & 0.82 ($\pm$ 0.13) \\
%         \bottomrule
%     \end{tabular}
%     \caption{Backtest results for the weekly forecasting challenge covering all thirteen submission weeks. PB corresponds to the sum of Pinball Losses averaged over folds during TSCV as before.}
%     \label{tab:challenge-backtest}
% \end{table}

\begin{table}[h]
    \centering
    \begin{tabular}{@{}lrrrrrr@{}}
        \toprule
        & \multicolumn{3}{c}{Bike} & \multicolumn{3}{c@{}}{Energy} \\
        \cmidrule(lr){2-4} \cmidrule(lr){5-7}
        Model & Pinball Loss & $\text{Cvg}_{0.5}$ & $\text{Cvg}_{0.05}$ & Pinball Loss & $\text{Cvg}_{0.5}$ & $\text{Cvg}_{0.05}$ \\
        \midrule
        Benchmark & 1453.64 & \textbf{0.51} & 0.92 & 8.46 & 0.21 & 0.84 \\
        Quantile Regression & 1166.25 & 0.57 & \textbf{0.95} & 4.90 & \textbf{0.43} & \textbf{0.96} \\
        XGBoost & 569.99 & 0.24 & 0.78 & 2.60 & 0.32 & 0.82 \\
        CatBoost (Plain) & 624.07 & 0.23 & 0.74 & 2.64 & 0.33 & 0.84 \\
        LightGBM & \textbf{523.57} & 0.39 & 0.86 & \textbf{2.57} & 0.34 & 0.82 \\
        \bottomrule
    \end{tabular}
    \caption{Backtest results for the weekly forecasting challenge covering all thirteen submission weeks. The standard deviation is omitted here for brevity as it is similar to the standard deviation in the validation backtest.}
    \label{tab:challenge-backtest}
\end{table}

There are several things to note here. First, the benchmark model generally performs worse in this period, with a big hit in coverage values and Pinball Loss, especially for the Energy Target. The second baseline model, the Linear Quantile Regression, performs quite similarly compared to previously in \cref{tab:bikes_results} and \cref{tab:energy_results}, also showing the best coverage values overall in this time frame. Second, the GBDT models more or less stayed consistent as well, with LightGBM performing the best on both targets regarding both Pinball Loss and coverage. However, the coverage values for XGBoost and CatBoost are much worse on the Bike Target. For example, compared to the validation backtest, CatBoost shows a loss of 13 and 7 percentage points in 50\% and 95\% PI Coverage, respectively. Therefore, a slight overfitting problem of XGBoost and CatBoost on the relatively small Bike Target regarding sample size is likely. LightGBM holds coverage values much better on this target, probably due to slightly larger settings for regularization parameters (cf. \cref{tab:model-config-bikes}).
