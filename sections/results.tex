\newpage
\section{Results}
\label{ch:Results}

In this chapter, the results of the forecasting challenge are discussed. First, in \cref{sec:Results:ComparisonModels}, a comparison of the models is made on the internal validation scheme employed throughout the project to select models. Second, in \cref{sec:Results:Backtest}, a backtest of the 13 submission weeks is performed to evaluate how the models would have performed during the challenge. 

\subsection{Comparison of models}
\label{sec:Results:ComparisonModels}

The results of the internal validation scheme using TSCV as described in \cref{sec:Methodology:Evaluation} are shown in \cref{tab:bikes_results} for the Bike Target and in \cref{tab:energy_results} for the Energy Target. 

\begin{table}[htp]
\centering
\resizebox{\columnwidth}{!}{
\begin{tabular}{@{}lrrrrr@{}}
\toprule
Model & Pinball Loss & $\text{IS}_{0.5}$ & $\text{IS}_{0.05}$ & $\text{Cvg}_{0.5}$ & $\text{Cvg}_{0.05}$ \\
\midrule
Benchmark & 1226.14 (± 751.49) & 1343.29 (± 829.37) & 2897.77 (± 2099.89) & 0.53 (± 0.29) & \textbf{0.95 (± 0.13)} \\
Quantile Regression & 1197.41 (± 602.68) & 1311.78 (± 698.27) & 2948.06 (± 1174.44) & \textbf{0.52 (± 0.26)} & 0.98 (± 0.07) \\
CatBoost (Ordered) & 852.67 (± 358.28) & 931.40 (± 402.08) & 1888.97 (± 1164.80) & 0.38 (± 0.21) & 0.85 (± 0.17) \\
XGBoost & 563.99 (± 259.31) & 602.74 (± 279.48) & 1618.93 (± 1114.08) & 0.31 (± 0.20) & 0.84 (± 0.16) \\
CatBoost (Plain) & 539.69 (± 301.24) & \textbf{570.01 (± 313.35)} & 1664.76 (± 1369.76) & 0.36 (± 0.21) & 0.81 (± 0.19) \\
LightGBM & \textbf{529.07 (± 251.59)} & 578.72 (± 285.86) & \textbf{1337.58 (± 646.38)} & 0.36 (± 0.23) & 0.90 (± 0.12) \\
\bottomrule
\end{tabular}}
\caption{Results of Timeseries Cross-Validation on the Bike Target for the full year 2024 with weekly shifting of sliding windows. Best values are highlighted in bold. \textit{Pinball Loss} refers to the sum of the pinball losses for all quantile levels, averaged over the folds in the TSCV (cf. \cref{sec:Methodology:Evaluation})}
\label{tab:bikes_results}
\end{table}

All GBDT models outperform the baseline models, namely the benchmark and linear quantile regression
regarding the Pinball Loss. However, the empirical coverages are much better for the baseline models.

\begin{table}[htp]
\centering
\resizebox{\columnwidth}{!}{
\begin{tabular}{@{}lrrrrr@{}}
\toprule
Model & Pinball Loss & $\text{IS}_{0.5}$ & $\text{IS}_{0.05}$ & $\text{Cvg}_{0.5}$ & $\text{Cvg}_{0.05}$ \\
\midrule
Benchmark & 5.12 (± 2.68) & 5.60 (± 2.92) & 11.20 (± 6.94) & \textbf{0.52 (± 0.30)} & \textbf{0.94 (± 0.13)} \\
Quantile Regression & 4.49 (± 2.37) & 4.60 (± 2.97) & 17.28 (± 1.61) & 0.47 (± 0.18) & 0.97 (± 0.05) \\
CatBoost (Ordered) & 3.55 (± 1.88) & 3.87 (± 1.92) & 8.59 (± 7.61) & 0.43 (± 0.14) & 0.89 (± 0.13) \\
XGBoost & 2.32 (± 1.21) & 2.47 (± 1.17) & 6.80 (± 6.57) & 0.37 (± 0.12) & 0.81 (± 0.16) \\
LightGBM & 2.30 (± 1.16) & 2.47 (± 1.15) & 6.42 (± 5.58) & 0.38 (± 0.13) & 0.83 (± 0.15) \\
CatBoost (Plain) & \textbf{2.25 (± 1.14)} & \textbf{2.42 (± 1.12)} & \textbf{5.98 (± 5.73)} & 0.39 (± 0.14) & 0.84 (± 0.15) \\
\bottomrule
\end{tabular}}
\caption{Results of Timeseries Cross-Validation on the Energy Target for the full year 2024 with weekly shifting of sliding windows. Best values are highlighted in bold.}
\label{tab:energy_results}
\end{table}

The coverage of the 95\% prediction interval $\text{Cvg}_{0.05}$ is below 85\% for most GBDT-Models and the coverage for the 50\% prediction interval is even worse. This means that the GBDT models probably still overfit the training data due to the included lagged target values, and thus are too confident in their predictions. It was observed that too many lags reduce the coverage substantially, but some are very helpful in reducing the pinball loss. A visual inspection of the narrow prediction intervals for the CatBoost model is given in the appendix in \cref{fig:Forecast-visualization}.
Only CatBoost achieves better coverage values when the ordered boosting type is used on the Energy
Target, at the cost of a much higher Pinball Loss. This can be visually evaluated with the calibration plots shown in \cref{fig:calibration-comparison} where the CatBoost calibration (\cref{fig:catboost-ordered-calibration}) is compared to the LightGBM calibration (\cref{fig:lgbm-calibration}).
\begin{figure}[htbp]
    \centering
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \includesvg[width=\linewidth]{images/catboost-ordered-energy-calibration.svg}
        \caption{CatBoost (Ordered)}
        \label{fig:catboost-ordered-calibration}
    \end{subfigure}%
    \begin{subfigure}[b]{0.5\textwidth}
        \centering
        \includesvg[width=\linewidth]{images/lgbm-energy-calibration.svg}
        \caption{LightGBM}
        \label{fig:lgbm-calibration}
    \end{subfigure}
    \caption{Calibration plots for two selected models on the Energy Target. It shows that the GBDT models tend to over-estimate the lower quantiles $\hat{q}_{0.025}$, $\hat{q}_{0.25}$ and under-estimate the upper levels $\hat{q}_{0.075}$, $\hat{q}_{0.975}$. CatBoost with the \texttt{boosting\_type=Ordered} parameter set, is slightly better calibrated than LightGBM at the cost of a higher Pinball Loss. XGBoost is very similar to LightGBM in this regard.}
    \label{fig:calibration-comparison}
\end{figure}

Calibration plots for all models on both targets, as well as other visualizations can be found in Appendix~\ref{appendix:additional-visualizations}.


CatBoost also supports the standard (Plain) gradient-boosting algorithm,
and with this, it performs on par with LightGBM and even outperforms it slightly on
the Energy Target. However, this is highly hyperparameter-dependent, and the standard
deviation is generally relatively high. The chosen hyper-parameters deviate from the default 
configuration to prevent overfitting and are described in more detail in Appendix~\ref{appendix:GBDT-configs}.\footnote{For example, the default parameters of LightGBM allow for trees with unlimited depth, restricting them only to a maximum of 32 leaves. This can lead to overfitting because nodes are expanded best first during tree construction. In addition, many randomization settings, such as subsampling of rows and columns, are disabled by default.}

\lipsum[1-7]

\subsection{Backtest for the weekly forecasting challenge}
\label{sec:Results:Backtest}

\lipsum[1-3]

\begin{table}[h]
    \centering
    \begin{tabular}{@{}lcccccc@{}}
        \toprule
        & \multicolumn{3}{c}{Bike} & \multicolumn{3}{c}{Energy} \\
        \cmidrule(lr){2-4} \cmidrule(lr){5-7}
        Model & PB & $\text{Cvg}_{0.5}$ & $\text{Cvg}_{0.05}$ & PB & $\text{Cvg}_{0.5}$ & $\text{Cvg}_{0.05}$ \\
        \midrule
        Benchmark & 1 & 2 & 3 & 4 & 5 & 6 \\
        Quantile Regression & 1 & 2 & 3 & 4 & 5 & 6 \\
        XGBoost & 1 & 2 & 3 & 4 & 5 & 6 \\
        CatBoost (Plain) & 1 & 2 & 3 & 4 & 5 & 6 \\
        LightGBM & 1 & 2 & 3 & 4 & 5 & 6 \\
        \bottomrule
    \end{tabular}
    \caption{Backtest results for the weekly forecasting challenge covering all thirteen submission weeks. PB corresponds to the sum of Pinball Losses averaged over folds during TSCV as before.}
    \label{tab:challenge-backtest}
\end{table}

\lipsum[1-2]